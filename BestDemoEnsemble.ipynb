{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Demo Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In this notebook, we look at how to use BestDemoEnsemble, an optimizer that uses an LLM as a judge to choose between various Automatic Few-Shot Learning optimizers based on their demos. We will test it on a simple QA program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install evaluate\n",
    "%pip install --upgrade pybind11\n",
    "%pip install --force-reinstall torch evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "from dspy.datasets.gsm8k import GSM8K\n",
    "from dspy.evaluate.evaluate import Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"It looks like you're testing the system. How can I assist you today?\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = dspy.LM(\"openai/gpt-4o-mini\")\n",
    "lm(\"testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.settings.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7473/7473 [00:00<00:00, 12740.80it/s]\n",
      "100%|██████████| 1319/1319 [00:00<00:00, 10745.89it/s]\n"
     ]
    }
   ],
   "source": [
    "gsm8k = GSM8K()\n",
    "gsm8k_trainset, gsm8k_devset = gsm8k.train, gsm8k.dev\n",
    "gsm8k_trainset = gsm8k_trainset[:50]\n",
    "gsm8k_devset = gsm8k_devset[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Answer the math problem with a single number.\"\"\"\n",
    "\n",
    "    question = dspy.InputField(desc='a math word problem')\n",
    "    answer = dspy.OutputField(desc='a single number')\n",
    "\n",
    "class QA(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "\n",
    "    def forward(self, question):\n",
    "        prediction = self.generate_answer(question=question)\n",
    "        return dspy.Prediction(answer=prediction.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ae7fae33774ec781e7a56bd4a9dfa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/200 [00:00<00:01, 108.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import LabeledFewShot\n",
    "from dspy.teleprompt import BootstrapFewShot\n",
    "from dspy.teleprompt import ClusterFewShot\n",
    "\n",
    "def validate_answer(example, pred, trace=None):\n",
    "    return dspy.evaluate.answer_exact_match(example, pred)\n",
    "\n",
    "vanilla_teleprompter = LabeledFewShot(k=6)\n",
    "bootstrap_teleprompter = BootstrapFewShot(max_labeled_demos=6, metric=validate_answer)\n",
    "cluster_teleprompter = ClusterFewShot(num_labeled_demos=6)\n",
    "\n",
    "compiled_vanilla = vanilla_teleprompter.compile(QA(), trainset=gsm8k_trainset)\n",
    "compiled_bootstrap = bootstrap_teleprompter.compile(QA(), trainset=gsm8k_trainset)\n",
    "compiled_cluster = cluster_teleprompter.compile(QA(), trainset=gsm8k_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'dspy.teleprompt.best_demo_ensemble' from 'c:\\\\Users\\\\Hamza\\\\dspy\\\\dspy\\\\teleprompt\\\\best_demo_ensemble.py'>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dspy.teleprompt)\n",
    "importlib.reload(dspy.teleprompt.cluster_fewshot)\n",
    "importlib.reload(dspy.teleprompt.best_demo_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The optimizer is initialized like normal, and when you compile, you pass in the programs that you want BestDemoEnsemble to choose between and the LM that will be the judge. In this case, we pass in programs compiled by LabeledFewShot, BootstrapFewShot, and ClusterFewShot respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import BestDemoEnsemble\n",
    "\n",
    "optimizer = BestDemoEnsemble()\n",
    "programs = [compiled_vanilla, compiled_bootstrap, compiled_cluster] # define the programs you want the optimizer to choose between\n",
    "\n",
    "compiled_program = optimizer.compile(programs, lm) # pass in the programs and the LM that will judge between program demos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Now let's run it on a random example from the devset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example({'question': 'Vanessa wants to buy a dress she saw at the mall, which costs $80, and she already has $20 in savings. Her parents give her $30 every week, but she also spends $10 each weekend at the arcades. How many weeks will she have to wait until she can gather enough money to buy the dress?', 'gold_reasoning': 'Vanessa needs $80 – $20 = $<<80-20=60>>60 to buy the dress. She manages to gather $30 - $10 = $<<30-10=20>>20 each week The number of weeks she has to wait is 60 ÷ 20 = <<60/20=3>>3 weeks.', 'answer': '3'}) (input_keys={'question'})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    answer='3'\n",
       ")"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gsm8k_devset[10])\n",
    "compiled_program(gsm8k_devset[10].question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### We see that it runs properly and predicts the correct answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### We can also see which program was chosen and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " {'difficulty': 'Program 1 presents problems that are moderately challenging, requiring a good understanding of basic arithmetic and logical reasoning without being overly complex.',\n",
       "  'coverage': 'This program covers a variety of scenarios, including exam scores, distance calculations, and comparisons, which provides a broad range of mathematical concepts and real-world applications.',\n",
       "  'semantic_shift': 'The examples in Program 1 maintain a low semantic shift, as they all revolve around straightforward calculations and comparisons, making it easier for users to follow the logic and reasoning across different problems.'})"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_program.chosen_program, compiled_program.justification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### It looks like the optimizer chose Program 1 (i.e. the second program: compiled_boostrap) and it provides a justification for its choice. Neat! \n",
    "###### Now let's try it with a different set of programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3473d710303484889dcf284395672ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " {'difficulty': 'Program 0 presents a variety of problems that are moderately difficult, requiring multi-step reasoning and basic arithmetic skills, which is appropriate for a wide range of learners.',\n",
       "  'coverage': 'Program 0 covers a broad range of topics including basic arithmetic, percentages, discounts, and averages, providing a comprehensive set of examples that can appeal to different interests and contexts.',\n",
       "  'semantic_shift': 'The examples in Program 0 maintain a low semantic shift, as they all revolve around practical, real-world scenarios involving calculations, making it easier for learners to follow the logic and reasoning across different examples.'})"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_teleprompter = ClusterFewShot(num_labeled_demos=16)\n",
    "compiled_cluster = cluster_teleprompter.compile(QA(), trainset=gsm8k_trainset)\n",
    "programs = [compiled_cluster, compiled_vanilla]\n",
    "\n",
    "compiled_program = optimizer.compile(programs, lm)\n",
    "compiled_program.chosen_program, compiled_program.justification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### This time, when choosing between two programs, one compiled with LabeledFewShot (compiled_vanilla) and one with ClusterFewShot with number of demos = 16, we see that it chooses the ClusterFewShot-compiled program (Program 0)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
